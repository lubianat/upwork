{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by downloading a subset of Wikidata containing only the items with  a linked website. \n",
    "\n",
    "This was done via https://tools.wmflabs.org/wdumps/#  filtering for items with the property P856.\n",
    "\n",
    "https://tools.wmflabs.org/wdumps/dump/470\n",
    "\n",
    "\n",
    "This dataset contains 60 million triples and 1.1 million entities, which is already 1/80th of the size of Wikidata.\n",
    "\n",
    "The file size is a bit shy of 1 Gb and can be found here too: https://sandbox.zenodo.org/record/642035#.XvqLTnVKg5k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "sites = pd.read_csv(\"sites-sample for tiago.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I don't get the full dump, I will try an work around. \n",
    "\n",
    "I will search Wikidata with SPARQL for the first URL.\n",
    "\n",
    "Then I will get the \"P31\" value of the item. \n",
    "\n",
    "Next, I will try SPARQL queries only for instances of that value, which reduces the search universe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'youtube.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites[\"name\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the online query for youTube: https://w.wiki/Vdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tmall.com'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites[\"name\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the online query for tmall.com: https://w.wiki/Vdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As they are both instances of websites, let's search the database just for those values. \n",
    "\n",
    "\n",
    "I got all instances of websites on Wikidata which contain an \"official website\" property. \n",
    "\n",
    "There are 8779 different website - domain pairs on Wikidata. This is the query for them: https://w.wiki/Vdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "websites_on_wikidata = pd.read_csv(\"websites_on_wikidata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.wikidata.org/entity/Q510954</td>\n",
       "      <td>Pearltrees</td>\n",
       "      <td>https://pearltrees.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.wikidata.org/entity/Q510968</td>\n",
       "      <td>PureMédias</td>\n",
       "      <td>http://www.ozap.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.wikidata.org/entity/Q513307</td>\n",
       "      <td>Alibaba.com</td>\n",
       "      <td>https://www.alibaba.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     item    itemLabel  \\\n",
       "0  http://www.wikidata.org/entity/Q510954   Pearltrees   \n",
       "1  http://www.wikidata.org/entity/Q510968   PureMédias   \n",
       "2  http://www.wikidata.org/entity/Q513307  Alibaba.com   \n",
       "\n",
       "                   website  \n",
       "0  https://pearltrees.com/  \n",
       "1     http://www.ozap.com/  \n",
       "2  https://www.alibaba.com  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websites_on_wikidata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trim the \"website\" colum, as we do not need the parts before or after the actual domain name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_out_domain_name(url):\n",
    "    try:\n",
    "        clean_name = url.split('/')[2]\n",
    "        try:\n",
    "            clean_name =   clean_name.split('www.')[1]\n",
    "            return(clean_name)\n",
    "        except:\n",
    "            return clean_name\n",
    "    except:\n",
    "        return(url)\n",
    "\n",
    "websites_on_wikidata[\"clean_website\"] = [strip_out_domain_name(url) for url  in websites_on_wikidata[\"website\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['website']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"website\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>website</th>\n",
       "      <th>clean_website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>http://www.wikidata.org/entity/Q866</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>https://www.youtube.com</td>\n",
       "      <td>youtube.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name                                 item itemLabel  \\\n",
       "0  youtube.com  http://www.wikidata.org/entity/Q866   YouTube   \n",
       "\n",
       "                   website clean_website  \n",
       "0  https://www.youtube.com   youtube.com  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_after_merge = sites.merge(websites_on_wikidata, left_on=\"name\", right_on=\"clean_website\", how=\"left\")\n",
    "sites_after_merge.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many of those domains have at least one associated item on Wikidata: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sites_after_merge.dropna()[\"name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "218 is not bad. That is already ~1/5th of the domains in the list. Lets find, then, the first exception.\n",
    "\n",
    "If it is not a website, what is it, then?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item</th>\n",
       "      <th>itemLabel</th>\n",
       "      <th>website</th>\n",
       "      <th>clean_website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>baidu.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>facebook.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>login.tmall.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wikipedia.org</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>360.cn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jd.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zoom.us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sina.com.cn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pages.tmall.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>netflix.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name item itemLabel website clean_website\n",
       "7         baidu.com  NaN       NaN     NaN           NaN\n",
       "9      facebook.com  NaN       NaN     NaN           NaN\n",
       "10  login.tmall.com  NaN       NaN     NaN           NaN\n",
       "12    wikipedia.org  NaN       NaN     NaN           NaN\n",
       "14           360.cn  NaN       NaN     NaN           NaN\n",
       "15           jd.com  NaN       NaN     NaN           NaN\n",
       "16          zoom.us  NaN       NaN     NaN           NaN\n",
       "18      sina.com.cn  NaN       NaN     NaN           NaN\n",
       "20  pages.tmall.com  NaN       NaN     NaN           NaN\n",
       "23      netflix.com  NaN       NaN     NaN           NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_after_merge[sites_after_merge['item'].isnull()].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now let's look for baidu.com on Wikidata SPARQL: https://w.wiki/Vdo \n",
    "\n",
    "Instance of web search engine; business and enterprise. But I would guess that there are a few too many businesses and enterprises on wikidata.\n",
    "\n",
    "Facebook: \n",
    "social networking service & data collection system: https://w.wiki/Vdp\n",
    "\n",
    "login.tmall.com:\n",
    "Not found. Maybe it should link to tmall?\n",
    "\n",
    "360.cn: https://w.wiki/Vds\n",
    "\n",
    "instance of a business\n",
    "\n",
    "jd.com:https://w.wiki/Vdu\n",
    "\n",
    "instance of a public company\n",
    "\n",
    "zoom.us: https://w.wiki/Vdw\n",
    "\n",
    "instance of public company\n",
    "\n",
    "\n",
    "# - \n",
    "\n",
    "There seem to be many instances of public companies. Let's search for those. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "public_companies_on_wikidata = pd.read_csv(\"public_companies_on_wikidata.csv\")\n",
    "public_companies_on_wikidata[\"clean_website\"] = [strip_out_domain_name(url) for url  in public_companies_on_wikidata[\"website\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sites_w_companies = sites.merge(public_companies_on_wikidata, left_on=\"name\", right_on=\"clean_website\", how=\"left\")\n",
    "len(set(sites_w_companies.dropna()[\"name\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only eleven. But these iterative, sequential searches may be alternatives for acelarating database query. \n",
    "I will have to explore it further.\n",
    "\n",
    "For now, we have:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_result = sites_after_merge[[\"name\", \"item\"]].dropna().append(sites_w_companies.dropna()[[\"name\", \"item\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_result.to_csv(\"partial_domain_to_wikidata_item.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
